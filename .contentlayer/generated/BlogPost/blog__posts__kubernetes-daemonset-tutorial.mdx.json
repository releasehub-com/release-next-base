{
  "title": "Kubernetes DaemonSets: A Detailed Introductory Tutorial",
  "summary": "Kubernetes deployment strategy: DaemonSets. What are they, what advantages they bring, and when to use them.",
  "publishDate": "Fri Jan 07 2022 17:33:41 GMT+0000 (Coordinated Universal Time)",
  "author": "dawid-ziolkowski",
  "readingTime": 5,
  "categories": [
    "kubernetes",
    "platform-engineering"
  ],
  "mainImage": "/blog-images/4b7c9ffacf7bcc55f80f55cf631007a5.jpg",
  "imageAlt": "keyboard kubernetes daemonsets",
  "showCTA": true,
  "ctaCopy": "Automate Kubernetes environment setup with Release for streamlined DaemonSets deployment and efficient container management.",
  "ctaLink": "https://release.com/signup?utm_source=blog&utm_medium=cta&utm_campaign=blog-cta&utm_content=kubernetes-daemonset-tutorial",
  "relatedPosts": [
    ""
  ],
  "ogImage": "/blog-images/4b7c9ffacf7bcc55f80f55cf631007a5.jpg",
  "excerpt": "Kubernetes deployment strategy: DaemonSets. What are they, what advantages they bring, and when to use them.",
  "tags": [
    "kubernetes",
    "platform-engineering"
  ],
  "ctaButton": "Try Release for Free",
  "body": {
    "raw": "\nKubernetes is one of the most popular container orchestrator systems. One of the reasons for its popularity is the fact that it offloads you from a lot of maintenance tasks when it comes to containers. It does a lot of stuff for you. For example, Kubernetes saves you a lot of time from planning where to deploy your microservices and spending even more time making sure that all the pods are distributed equally across all available nodes.\n\nBut as with everything, there is no one solution that suits all use cases. That's why Kubernetes has a few different types of deployment strategies. In this post, you'll learn what DaemonSets are, what advantages they bring, and when to use them.\n\n### What Is Kubernetes Deployment?\n\nBefore we dive into DaemonSets, let's make sure we understand the general concept of Kubernetes workflows. [Kubernetes](https://en.wikipedia.org/wiki/Kubernetes) is quite a complex system with a lot of components and options. There are many choices for networking, storage, scaling, etc. But the core function of Kubernetes is to run containers. So, if you want to instruct Kubernetes to run a container (as a [pod](https://kubernetes.io/docs/concepts/workloads/pods/)), you need to create a workflow.\n\n![](/blog-images/629886596ac84b7eb89ebf0aa8228d19.png)\n\nAs with anything else on Kubernetes, there are a few configuration options for workflows. The most common type of workflow is Deployment. Creating a Deployment means telling Kubernetes, \"Please run a container from this Docker image.\" This is, of course, a hugely simplified explanation, but you get the idea. To create a workflow of a Deployment type, you need to include just that in your typical Kubernetes YAML definition:\n\n```yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n\t(...)\nspec:\n\t(...)\n\n```\n\n### Deployment in Action\n\nSo what happens when you create a Deployment? Kubernetes will first find appropriate nodes to run your pod. One of the main criteria for being \"appropriate\" is the load on the node. Kubernetes, by default, will try to distribute the load across all nodes. So, for example, say you have five nodes, and on four of them you have 10 pods running, whereas the last one is running only eight. There's a high chance that Kubernetes will schedule any new Deployment on that last node. Also, when one of the nodes becomes unavailable for whatever reason, Kubernetes will try to reschedule all the pods that were running on that node to the remaining nodes, and again, it will try to distribute these pods to all nodes.\n\nAll of this decision-making on where to schedule containers is happening under the hood, and you don't need to worry about where your pods will be scheduled. This is one of the main features of Kubernetes. You just add new nodes whenever your cluster becomes saturated, and Kubernetes does all the management for you.\n\n### Different Types of Workflows\n\nAll of the above is just Kubernetes' default behavior. Of course, sometimes you actually may want to have more control over the scheduling process. You may want to schedule some microservices on specific nodes, something that's often used with multiple node pools. For example, you may want to add a few nodes with high-performance graphics cards and schedule some big data for AI processing microservices specifically on these nodes. This is just one example. There are more use cases where you may want a different behavior from Kubernetes than the default \"schedule my pods anywhere.\" One such use case is the need for scheduling a copy of a pod on every single node. Let me now introduce you to DaemonSets.\n\n### Enter DaemonSet\n\nSo why would you want to schedule the same containers on every single node? There are many possible reasons. The most common one is the need for scheduling a \"daemon\"-type application that needs to perform some action on every node. Common examples are logs or metrics-gathering daemons. It's also possible to schedule a copy of a pod not on all nodes but on a subset of them. This can be useful for scheduling a daemon-type pod, for example, only on a specific node pool.\n\nFor instance, if you want to get metrics (like CPU or RAM usage) from each node, the best option is to schedule a container on every node that will gather these metrics from each individual node. Why not simply schedule one container instead that will gather metrics from all nodes? Well, you would run the risk that the node on which the metrics are running dies for whatever reason, and you'd lose metrics from the whole cluster. Of course, Kubernetes would redeploy that service on another node. But depending on how busy your cluster is, that could take a while, and therefore, you would miss some of the data. In the case of metrics, maybe it wouldn't be such a big deal, but imagine losing logs from all containers for a moment.\n\nBut besides these common use cases, you may simply want to have a copy of the same container on every node for any application-specific use case—things like node-local application caches, for example.\n\n### DaemonSets in Detail\n\nNow that we understand the need behind DaemonSets, let's talk about them in more detail. We know already that the main point of a DaemonSet is to ensure that all nodes are running a copy of a pod. Therefore, unlike with a typical Kubernetes Deployment, you don't specify how many pods you want to run. Kubernetes will automatically run as many pods as you have nodes. Another difference from normal deployment is the fact that in case of a node being removed from the cluster, Kubernetes won't move the pod that belongs to the DaemonSet to a different node but instead will simply destroy it.\n\nSo how do you create a workflow with DaemonSet? Very similarly to a normal Deployment. In fact, as with any other Kubernetes definition, you need to prepare a YAML definition with **apiVersion**, **kind**, and **metadata** fields. However, instead of **Deployment**, the **kind** value, in this case, will be **DaemonSet**. So an example DaemonSet YAML definition could look like this:\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-daemon\nspec:\n  selector:\n    matchLabels:\n      name: fluentd-daemon\n  template:\n    metadata:\n      labels:\n        name: fluentd-daemon\n    spec:\n      containers:\n        - image: fluent/fluentd\n          name: fluentd-daemon\n```\n\nFollowing the idea of a DaemonSet, the above definition will deploy a **fluentd** pod on every node in the cluster. Kubernetes will make sure that there's only one pod on every node. For example, if you have five nodes, you'll have five **fluentd** pods running. If one of the nodes becomes unavailable, you'll have four **fluentd** pods running.\n\n![](/blog-images/93e833a771bb0786e80b1ab5172856b9.png)\n\n### Summary\n\nKubernetes DaemonSets can be a bit tricky to understand at first. They may seem like something against the whole point of Kubernetes. But just like with anything else, there are use cases where something that seems odd is actually useful. In the case of Kubernetes DaemonSets, they're quite commonly used for things like logs or monitoring. Also, don't forget that the main advantages of Kubernetes are flexibility and the ability to adjust it to different companies and infrastructures.\n\nOf course, no one will force you to use DaemonSets. It's totally fine to not use them if you feel like you don't need them. But on the other hand, when you do actually need a daemon-like functionality, it's way better and easier to use DaemonSets than trying to achieve the same with normal Kubernetes Deployment. If you want to learn more about Kubernetes, check out [this post about advanced concepts for Kubernetes pods](https://releasehub.com/blog/kubernetes-pods-advanced-concepts-explained).\n",
    "code": "var Component=(()=>{var c=Object.create;var s=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,p=Object.prototype.hasOwnProperty;var y=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),g=(t,e)=>{for(var o in e)s(t,o,{get:e[o],enumerable:!0})},r=(t,e,o,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of m(e))!p.call(t,a)&&a!==o&&s(t,a,{get:()=>e[a],enumerable:!(i=u(e,a))||i.enumerable});return t};var b=(t,e,o)=>(o=t!=null?c(f(t)):{},r(e||!t||!t.__esModule?s(o,\"default\",{value:t,enumerable:!0}):o,t)),w=t=>r(s({},\"__esModule\",{value:!0}),t);var d=y((x,l)=>{l.exports=_jsx_runtime});var K={};g(K,{default:()=>D,frontmatter:()=>k});var n=b(d()),k={title:\"Kubernetes DaemonSets: A Detailed Introductory Tutorial\",summary:\"Kubernetes deployment strategy: DaemonSets. What are they, what advantages they bring, and when to use them.\",publishDate:\"Fri Jan 07 2022 17:33:41 GMT+0000 (Coordinated Universal Time)\",author:\"dawid-ziolkowski\",readingTime:5,categories:[\"kubernetes\",\"platform-engineering\"],mainImage:\"/blog-images/4b7c9ffacf7bcc55f80f55cf631007a5.jpg\",imageAlt:\"keyboard kubernetes daemonsets\",showCTA:!0,ctaCopy:\"Automate Kubernetes environment setup with Release for streamlined DaemonSets deployment and efficient container management.\",ctaLink:\"https://release.com/signup?utm_source=blog&utm_medium=cta&utm_campaign=blog-cta&utm_content=kubernetes-daemonset-tutorial\",relatedPosts:[\"\"],ogImage:\"/blog-images/4b7c9ffacf7bcc55f80f55cf631007a5.jpg\",excerpt:\"Kubernetes deployment strategy: DaemonSets. What are they, what advantages they bring, and when to use them.\",tags:[\"kubernetes\",\"platform-engineering\"],ctaButton:\"Try Release for Free\"};function h(t){let e=Object.assign({p:\"p\",h3:\"h3\",a:\"a\",span:\"span\",img:\"img\",pre:\"pre\",code:\"code\",strong:\"strong\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:\"Kubernetes is one of the most popular container orchestrator systems. One of the reasons for its popularity is the fact that it offloads you from a lot of maintenance tasks when it comes to containers. It does a lot of stuff for you. For example, Kubernetes saves you a lot of time from planning where to deploy your microservices and spending even more time making sure that all the pods are distributed equally across all available nodes.\"}),`\n`,(0,n.jsx)(e.p,{children:\"But as with everything, there is no one solution that suits all use cases. That's why Kubernetes has a few different types of deployment strategies. In this post, you'll learn what DaemonSets are, what advantages they bring, and when to use them.\"}),`\n`,(0,n.jsxs)(e.h3,{id:\"what-is-kubernetes-deployment\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#what-is-kubernetes-deployment\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"What Is Kubernetes Deployment?\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Before we dive into DaemonSets, let's make sure we understand the general concept of Kubernetes workflows. \",(0,n.jsx)(e.a,{href:\"https://en.wikipedia.org/wiki/Kubernetes\",children:\"Kubernetes\"}),\" is quite a complex system with a lot of components and options. There are many choices for networking, storage, scaling, etc. But the core function of Kubernetes is to run containers. So, if you want to instruct Kubernetes to run a container (as a \",(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/workloads/pods/\",children:\"pod\"}),\"), you need to create a workflow.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/blog-images/629886596ac84b7eb89ebf0aa8228d19.png\",alt:\"\"})}),`\n`,(0,n.jsx)(e.p,{children:'As with anything else on Kubernetes, there are a few configuration options for workflows. The most common type of workflow is Deployment. Creating a Deployment means telling Kubernetes, \"Please run a container from this Docker image.\" This is, of course, a hugely simplified explanation, but you get the idea. To create a workflow of a Deployment type, you need to include just that in your typical Kubernetes YAML definition:'}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n\t(...)\nspec:\n\t(...)\n\n`})}),`\n`,(0,n.jsxs)(e.h3,{id:\"deployment-in-action\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#deployment-in-action\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Deployment in Action\"]}),`\n`,(0,n.jsx)(e.p,{children:`So what happens when you create a Deployment? Kubernetes will first find appropriate nodes to run your pod. One of the main criteria for being \"appropriate\" is the load on the node. Kubernetes, by default, will try to distribute the load across all nodes. So, for example, say you have five nodes, and on four of them you have 10 pods running, whereas the last one is running only eight. There's a high chance that Kubernetes will schedule any new Deployment on that last node. Also, when one of the nodes becomes unavailable for whatever reason, Kubernetes will try to reschedule all the pods that were running on that node to the remaining nodes, and again, it will try to distribute these pods to all nodes.`}),`\n`,(0,n.jsx)(e.p,{children:\"All of this decision-making on where to schedule containers is happening under the hood, and you don't need to worry about where your pods will be scheduled. This is one of the main features of Kubernetes. You just add new nodes whenever your cluster becomes saturated, and Kubernetes does all the management for you.\"}),`\n`,(0,n.jsxs)(e.h3,{id:\"different-types-of-workflows\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#different-types-of-workflows\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Different Types of Workflows\"]}),`\n`,(0,n.jsx)(e.p,{children:`All of the above is just Kubernetes' default behavior. Of course, sometimes you actually may want to have more control over the scheduling process. You may want to schedule some microservices on specific nodes, something that's often used with multiple node pools. For example, you may want to add a few nodes with high-performance graphics cards and schedule some big data for AI processing microservices specifically on these nodes. This is just one example. There are more use cases where you may want a different behavior from Kubernetes than the default \"schedule my pods anywhere.\" One such use case is the need for scheduling a copy of a pod on every single node. Let me now introduce you to DaemonSets.`}),`\n`,(0,n.jsxs)(e.h3,{id:\"enter-daemonset\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#enter-daemonset\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Enter DaemonSet\"]}),`\n`,(0,n.jsx)(e.p,{children:`So why would you want to schedule the same containers on every single node? There are many possible reasons. The most common one is the need for scheduling a \"daemon\"-type application that needs to perform some action on every node. Common examples are logs or metrics-gathering daemons. It's also possible to schedule a copy of a pod not on all nodes but on a subset of them. This can be useful for scheduling a daemon-type pod, for example, only on a specific node pool.`}),`\n`,(0,n.jsx)(e.p,{children:\"For instance, if you want to get metrics (like CPU or RAM usage) from each node, the best option is to schedule a container on every node that will gather these metrics from each individual node. Why not simply schedule one container instead that will gather metrics from all nodes? Well, you would run the risk that the node on which the metrics are running dies for whatever reason, and you'd lose metrics from the whole cluster. Of course, Kubernetes would redeploy that service on another node. But depending on how busy your cluster is, that could take a while, and therefore, you would miss some of the data. In the case of metrics, maybe it wouldn't be such a big deal, but imagine losing logs from all containers for a moment.\"}),`\n`,(0,n.jsx)(e.p,{children:\"But besides these common use cases, you may simply want to have a copy of the same container on every node for any application-specific use case\\u2014things like node-local application caches, for example.\"}),`\n`,(0,n.jsxs)(e.h3,{id:\"daemonsets-in-detail\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#daemonsets-in-detail\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"DaemonSets in Detail\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Now that we understand the need behind DaemonSets, let's talk about them in more detail. We know already that the main point of a DaemonSet is to ensure that all nodes are running a copy of a pod. Therefore, unlike with a typical Kubernetes Deployment, you don't specify how many pods you want to run. Kubernetes will automatically run as many pods as you have nodes. Another difference from normal deployment is the fact that in case of a node being removed from the cluster, Kubernetes won't move the pod that belongs to the DaemonSet to a different node but instead will simply destroy it.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"So how do you create a workflow with DaemonSet? Very similarly to a normal Deployment. In fact, as with any other Kubernetes definition, you need to prepare a YAML definition with \",(0,n.jsx)(e.strong,{children:\"apiVersion\"}),\", \",(0,n.jsx)(e.strong,{children:\"kind\"}),\", and \",(0,n.jsx)(e.strong,{children:\"metadata\"}),\" fields. However, instead of \",(0,n.jsx)(e.strong,{children:\"Deployment\"}),\", the \",(0,n.jsx)(e.strong,{children:\"kind\"}),\" value, in this case, will be \",(0,n.jsx)(e.strong,{children:\"DaemonSet\"}),\". So an example DaemonSet YAML definition could look like this:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-daemon\nspec:\n  selector:\n  \\xA0 matchLabels:\n  \\xA0 \\xA0 name: fluentd-daemon\n  template:\n  \\xA0 metadata:\n  \\xA0 \\xA0 labels:\n  \\xA0 \\xA0 \\xA0 name: fluentd-daemon\n  \\xA0 spec:\n  \\xA0 \\xA0 containers:\n  \\xA0 \\xA0 \\xA0 - image: fluent/fluentd\n  \\xA0 \\xA0 \\xA0 \\xA0 name: fluentd-daemon\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Following the idea of a DaemonSet, the above definition will deploy a \",(0,n.jsx)(e.strong,{children:\"fluentd\"}),\" pod on every node in the cluster. Kubernetes will make sure that there's only one pod on every node. For example, if you have five nodes, you'll have five \",(0,n.jsx)(e.strong,{children:\"fluentd\"}),\" pods running. If one of the nodes becomes unavailable, you'll have four \",(0,n.jsx)(e.strong,{children:\"fluentd\"}),\" pods running.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/blog-images/93e833a771bb0786e80b1ab5172856b9.png\",alt:\"\"})}),`\n`,(0,n.jsxs)(e.h3,{id:\"summary\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#summary\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Summary\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Kubernetes DaemonSets can be a bit tricky to understand at first. They may seem like something against the whole point of Kubernetes. But just like with anything else, there are use cases where something that seems odd is actually useful. In the case of Kubernetes DaemonSets, they're quite commonly used for things like logs or monitoring. Also, don't forget that the main advantages of Kubernetes are flexibility and the ability to adjust it to different companies and infrastructures.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Of course, no one will force you to use DaemonSets. It's totally fine to not use them if you feel like you don't need them. But on the other hand, when you do actually need a daemon-like functionality, it's way better and easier to use DaemonSets than trying to achieve the same with normal Kubernetes Deployment. If you want to learn more about Kubernetes, check out \",(0,n.jsx)(e.a,{href:\"https://releasehub.com/blog/kubernetes-pods-advanced-concepts-explained\",children:\"this post about advanced concepts for Kubernetes pods\"}),\".\"]})]})}function v(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(h,t)})):h(t)}var D=v;return w(K);})();\n;return Component;"
  },
  "_id": "blog/posts/kubernetes-daemonset-tutorial.mdx",
  "_raw": {
    "sourceFilePath": "blog/posts/kubernetes-daemonset-tutorial.mdx",
    "sourceFileName": "kubernetes-daemonset-tutorial.mdx",
    "sourceFileDir": "blog/posts",
    "contentType": "mdx",
    "flattenedPath": "blog/posts/kubernetes-daemonset-tutorial"
  },
  "type": "BlogPost",
  "computedSlug": "kubernetes-daemonset-tutorial"
}