{
  "title": "How Do You Make Kubernetes Config Files Not Suck?",
  "summary": "I know that when I try out a new product if it’s hard to see what it does quickly I usually move on.",
  "publishDate": "Wed Feb 03 2021 05:22:59 GMT+0000 (Coordinated Universal Time)",
  "author": "regis-wilson",
  "readingTime": 4,
  "categories": [
    "kubernetes",
    "platform-engineering"
  ],
  "mainImage": "/blog-images/ade0049406c93db8b827edd0f4966435.jpg",
  "imageAlt": "Pile of trash representing bad Kubernetes Config Files",
  "showCTA": true,
  "ctaCopy": "Simplify Kubernetes config management with Release's ephemeral environments, preventing production mishaps and streamlining cluster connections.",
  "ctaLink": "https://release.com/signup?utm_source=blog&utm_medium=cta&utm_campaign=blog-cta&utm_content=how-to-make-kubernetes-config-files-not-suck",
  "relatedPosts": [
    ""
  ],
  "ogImage": "/blog-images/ade0049406c93db8b827edd0f4966435.jpg",
  "excerpt": "I know that when I try out a new product if it’s hard to see what it does quickly I usually move on.",
  "tags": [
    "kubernetes",
    "platform-engineering"
  ],
  "ctaButton": "Try Release for Free",
  "body": {
    "raw": "\n### How Do You Make Kubernetes Config Files Not Suck?\n\nNothing makes me break out in a panic and cold sweat faster than someone saying, “Edit the YAML config files and push it to production.” I have so many welts and scars on my backside from years of YAML file mishaps in production. I have also personally witnessed and had to try to fix many more such production outages due to YAML files being edited and pushed to production. In some cases, just figuring out what was wrong with the YAML file, much less how to fix it took seemingly endless minutes of frantic searching and scrambling to save a production website that was down and losing money.\n\nPlease note, this is not a JSON vs. YAML or Yet Another Data Language vs. YAML(because YAML Ain’t Markup Language) religious war! You can actually use JSON for Kubernetes configuration files _if you want to_. The real issue is that _there are so many_ of them and _they repeat so often_ and _I don’t know what to put where_ or even _where to find out where to start_.\n\nThere is a very good page of [best practices](https://kubernetes.io/docs/concepts/configuration/overview/) and the documentation for Kubernetes does tend to be surprisingly useful. There are tons of useful videos on Youtube that are helpful, so I am not even complaining about that.\n\nThe problem begins with just trying to connect to a cluster the very first time! The mysteries of the ~/.kube/ directory arise swiftly from the depths and bottom out the boat on your Kubernetes journey before you’ve even begun. Fortunately, there are a lot of ways you can avoid editing or creating the configuration files with a few steps that were enlightening to me; hopefully they will be useful for you.\n\nI like to keep my configuration files separated and specify them explicitly. This prevents me from, say, deploying or sending commands to a production environment by accident. I also tend to have a few pre-production or even developer environments laying about and I want to choose which one I interact with each time. I also don’t want to overwrite any important credentials I may have stored in a default location so I like to keep all my files separated away from the default file names if possible.\n\n### Prerequisites\n\nWe use Amazon Web Services (AWS) managed Kubernetes service called EKS and so my configuration setup is pretty AWS-centric, but by no means unusual. I also run a local Ubuntu 20.20 instance on Windows 10, so even though I have Windows, I’m not a Powershell or Command Prompt user. This will be a Linux/AWS configuration example but it should be usable on a Macintosh, or with proper translation, a native Windows environment. Similarly, you can use the same approach for other cloud providers or on-premise clusters.\n\nYou will need an AWS account, AWS credentials (preferably an Admin, but if your cluster is already created, then just a user), the AWS CLI, EKSCTL, Kubectl commands installed.\n\n#### Your AWS credentials\n\nThe first step is to set up your AWS credentials. You can setup default credentials just by typing\n\n```yaml\n\n$ aws configure\nAWS Access Key ID [None]: accesskey\nAWS Secret Access Key [None]: secretkey\nDefault region name [None]: us-west-2\nDefault output format [None]:\n\n$ aws ec2 describe-instances\n\n```\n\nThis works well for defaults or if you’ve never setup AWS credentials on your computer before. However, I will always move these credentials into a profile that I can access only when needed. Edit your ~/.aws/credentials file with an editor and move your credentials from \\[default\\] to some other named profile, for example if you have a production and development account, your file might look like the following.\n\n```yaml\n\n[default]\n\n[production]\naws_access_key_id = SOMETHING\naws_secret_access_key = SOMETHINGELSE\n\n[development]\naws_access_key_id = SOMETHING\naws_secret_access_key = SOMETHINGELSE\n\n```\n\nThe great thing about this setup is you can choose which environment you want to deploy into, and you won’t accidentally deploy to production if you switch terminal windows or pick up where you left off after a break. On the downside, you will have to remember to always specify your profile in one of several ways, for example:\n\n```yaml\n$ AWS_PROFILE=production aws ec2 describe-instances\n$ aws ec2 describe-instances --profile=production\n```\n\nYou may find that less than convenient, but I enjoy it. I even go so far as not specifying a default region, so that I have to specify both profile and region in my commands (but it prevents me from making a lot of mistakes I would otherwise make):\n\n```yaml\n$ AWS_DEFAULT_REGION=us-west-2 AWS_PROFILE=production aws ec2 describe-instances\n$ aws ec2 describe-instances --profile=production --region=us-west-2\n```\n\nAnd finally, in [Terraform](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#shared-credentials-file), you can easily switch environments by using this existing setup and specifying an input variable for the provider profile.\n\n```yaml\nprovider {\nregion = var.aws_region\nprofile = var.credentials_profile\n}\n```\n\n### The EKS Cluster Configuration\n\nNow, you need to connect to an EKS cluster by generating a file which is known as a kubeconfig. By default, the kubeconfig files will be merged or written into your ~/.kube/config file, or if you have a $KUBECONFIG variable set, into the first file in that list (more on the $KUBECONFIG variable later).\n\nAgain, I break out in hives around anything to do with YAML files and merging multiple configurations into one default file sounds like an easy recipe for disaster or rolling out the wrong changes to production late at night. Ideally, I’d like to keep all my configurations separate and specify them when I need them. I also want to avoid editing files or updating labels in dense, hard to read YAML.\n\nIf you have more than one EKS cluster, and perhaps in separate AWS accounts, I want to make sure I keep them straight. The first step is to create a cluster configuration file and save it to a specific file:\n\n```yaml\n$ AWS_PROFILE=production AWS_DEFAULT_REGION=us-west-2 \\\naws eks update-kubeconfig --name=prodEKS --alias=production \\\n--kubeconfig=~/.kube/config-prod-us-west-2\n```\n\nOne of the great tools you should check out is EKSCTL which has a similar use case:\n\n```yaml\n$ eksctl utils write-kubeconfig --cluster=prodEKS \\\n--kubeconfig=~/.kube/config-prod-us-west-2 \\\n--set-kubeconfig-context --profile=production \\\n--region=us-west-2\n```\n\nI also like to use the --auto-kubeconfig option instead of --kubeconfig because it will save the file in ~/.kube/clusters/<clustername> by default.</clustername>\n\nNow, you can access your cluster by name, for example:\n\n```yaml\n$ AWS_PROFILE=prod kubectl get pods -A -o wide \\\n--kubeconfig=~/.kube/config-prod-us-west-2\n```\n\nSo it gets a bit hairy to keep listing the file to specify which cluster you want to connect with. There must be a better way to do this, and there is luckily a way to specify a [context and merge files](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/#the-kubeconfig-environment-variable) to get this to work.\n\nSo let’s say that all your cluster configurations are stored in separate files (which I like) and they all have a convention of starting with ~/.kube/config-\\* or exist in a subdirectory like ~/.kube/clusters/\\*. Now you can create a KUBECONFIG colon-separated list of the files like so:\n\n```\n\nFILES=(~/.kube/config-*); IFS=: eval 'export KUBECONFIG=\"${FILES[*]}\"'\n\n```\n\nAdd the above snippet to your ~/.bash_aliases (or whatever bashrc script you prefer) and then start a new shell and you’ll be able to select a cluster by context:\n\n```\n\n$ exec bash -l # This just loads my exports if I have updated anything\n$ AWS_PROFILE=production kubectl get pods -A -o wide --context=production\n\n```\n\nSo you will need to specify your AWS profile (to gain access credentials to your assumed role for EKS) and also specify the context in order to choose a cluster to connect to. But I find it fairly usable and keeps all my configuration files in separate locations while still being relatively easy to maintain and manage. I also remove the accidental possibility of accessing the incorrect cluster or environment and wreaking havoc.\n\n### Conclusion\n\nIt is possible to keep YAML file configuration and management of EKS kubernetes clusters separate and yet accessible with some flags that switch into the correct environment. Adding and removing clusters and credentials is easily managed in the filesystem and without editing files directly. Also, defaults are removed so that a command does not get executed on the wrong cluster inadvertently.\n",
    "code": "var Component=(()=>{var d=Object.create;var a=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var g=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),y=(t,e)=>{for(var o in e)a(t,o,{get:e[o],enumerable:!0})},r=(t,e,o,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let i of p(e))!m.call(t,i)&&i!==o&&a(t,i,{get:()=>e[i],enumerable:!(s=h(e,i))||s.enumerable});return t};var w=(t,e,o)=>(o=t!=null?d(f(t)):{},r(e||!t||!t.__esModule?a(o,\"default\",{value:t,enumerable:!0}):o,t)),b=t=>r(a({},\"__esModule\",{value:!0}),t);var l=g((N,c)=>{c.exports=_jsx_runtime});var S={};y(S,{default:()=>I,frontmatter:()=>k});var n=w(l()),k={title:\"How Do You Make Kubernetes Config Files Not Suck?\",summary:\"I know that when I try out a new product if it\\u2019s hard to see what it does quickly I usually move on.\",publishDate:\"Wed Feb 03 2021 05:22:59 GMT+0000 (Coordinated Universal Time)\",author:\"regis-wilson\",readingTime:4,categories:[\"kubernetes\",\"platform-engineering\"],mainImage:\"/blog-images/ade0049406c93db8b827edd0f4966435.jpg\",imageAlt:\"Pile of trash representing bad Kubernetes Config Files\",showCTA:!0,ctaCopy:\"Simplify Kubernetes config management with Release's ephemeral environments, preventing production mishaps and streamlining cluster connections.\",ctaLink:\"https://release.com/signup?utm_source=blog&utm_medium=cta&utm_campaign=blog-cta&utm_content=how-to-make-kubernetes-config-files-not-suck\",relatedPosts:[\"\"],ogImage:\"/blog-images/ade0049406c93db8b827edd0f4966435.jpg\",excerpt:\"I know that when I try out a new product if it\\u2019s hard to see what it does quickly I usually move on.\",tags:[\"kubernetes\",\"platform-engineering\"],ctaButton:\"Try Release for Free\"};function u(t){let e=Object.assign({h3:\"h3\",a:\"a\",span:\"span\",p:\"p\",em:\"em\",h4:\"h4\",pre:\"pre\",code:\"code\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.h3,{id:\"how-do-you-make-kubernetes-config-files-not-suck\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#how-do-you-make-kubernetes-config-files-not-suck\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"How Do You Make Kubernetes Config Files Not Suck?\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Nothing makes me break out in a panic and cold sweat faster than someone saying, \\u201CEdit the YAML config files and push it to production.\\u201D I have so many welts and scars on my backside from years of YAML file mishaps in production. I have also personally witnessed and had to try to fix many more such production outages due to YAML files being edited and pushed to production. In some cases, just figuring out what was wrong with the YAML file, much less how to fix it took seemingly endless minutes of frantic searching and scrambling to save a production website that was down and losing money.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Please note, this is not a JSON vs. YAML or Yet Another Data Language vs. YAML(because YAML Ain\\u2019t Markup Language) religious war! You can actually use JSON for Kubernetes configuration files \",(0,n.jsx)(e.em,{children:\"if you want to\"}),\". The real issue is that \",(0,n.jsx)(e.em,{children:\"there are so many\"}),\" of them and \",(0,n.jsx)(e.em,{children:\"they repeat so often\"}),\" and \",(0,n.jsx)(e.em,{children:\"I don\\u2019t know what to put where\"}),\" or even \",(0,n.jsx)(e.em,{children:\"where to find out where to start\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"There is a very good page of \",(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/configuration/overview/\",children:\"best practices\"}),\" and the documentation for Kubernetes does tend to be surprisingly useful. There are tons of useful videos on Youtube that are helpful, so I am not even complaining about that.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The problem begins with just trying to connect to a cluster the very first time! The mysteries of the ~/.kube/ directory arise swiftly from the depths and bottom out the boat on your Kubernetes journey before you\\u2019ve even begun. Fortunately, there are a lot of ways you can avoid editing or creating the configuration files with a few steps that were enlightening to me; hopefully they will be useful for you.\"}),`\n`,(0,n.jsx)(e.p,{children:\"I like to keep my configuration files separated and specify them explicitly. This prevents me from, say, deploying or sending commands to a production environment by accident. I also tend to have a few pre-production or even developer environments laying about and I want to choose which one I interact with each time. I also don\\u2019t want to overwrite any important credentials I may have stored in a default location so I like to keep all my files separated away from the default file names if possible.\"}),`\n`,(0,n.jsxs)(e.h3,{id:\"prerequisites\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#prerequisites\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Prerequisites\"]}),`\n`,(0,n.jsx)(e.p,{children:\"We use Amazon Web Services (AWS) managed Kubernetes service called EKS and so my configuration setup is pretty AWS-centric, but by no means unusual. I also run a local Ubuntu 20.20 instance on Windows 10, so even though I have Windows, I\\u2019m not a Powershell or Command Prompt user. This will be a Linux/AWS configuration example but it should be usable on a Macintosh, or with proper translation, a native Windows environment. Similarly, you can use the same approach for other cloud providers or on-premise clusters.\"}),`\n`,(0,n.jsx)(e.p,{children:\"You will need an AWS account, AWS credentials (preferably an Admin, but if your cluster is already created, then just a user), the AWS CLI, EKSCTL, Kubectl commands installed.\"}),`\n`,(0,n.jsxs)(e.h4,{id:\"your-aws-credentials\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#your-aws-credentials\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Your AWS credentials\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The first step is to set up your AWS credentials. You can setup default credentials just by typing\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`\n$ aws configure\nAWS Access Key ID [None]: accesskey\nAWS Secret Access Key [None]: secretkey\nDefault region name [None]: us-west-2\nDefault output format [None]:\n\n$ aws ec2 describe-instances\n\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"This works well for defaults or if you\\u2019ve never setup AWS credentials on your computer before. However, I will always move these credentials into a profile that I can access only when needed. Edit your ~/.aws/credentials file with an editor and move your credentials from [default] to some other named profile, for example if you have a production and development account, your file might look like the following.\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`\n[default]\n\n[production]\naws_access_key_id = SOMETHING\naws_secret_access_key = SOMETHINGELSE\n\n[development]\naws_access_key_id = SOMETHING\naws_secret_access_key = SOMETHINGELSE\n\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"The great thing about this setup is you can choose which environment you want to deploy into, and you won\\u2019t accidentally deploy to production if you switch terminal windows or pick up where you left off after a break. On the downside, you will have to remember to always specify your profile in one of several ways, for example:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`$ AWS_PROFILE=production aws ec2 describe-instances\n$ aws ec2 describe-instances --profile=production\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"You may find that less than convenient, but I enjoy it. I even go so far as not specifying a default region, so that I have to specify both profile and region in my commands (but it prevents me from making a lot of mistakes I would otherwise make):\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`$ AWS_DEFAULT_REGION=us-west-2 AWS_PROFILE=production aws ec2 describe-instances\n$ aws ec2 describe-instances --profile=production --region=us-west-2\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"And finally, in \",(0,n.jsx)(e.a,{href:\"https://registry.terraform.io/providers/hashicorp/aws/latest/docs#shared-credentials-file\",children:\"Terraform\"}),\", you can easily switch environments by using this existing setup and specifying an input variable for the provider profile.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`provider {\nregion = var.aws_region\nprofile = var.credentials_profile\n}\n`})}),`\n`,(0,n.jsxs)(e.h3,{id:\"the-eks-cluster-configuration\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#the-eks-cluster-configuration\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"The EKS Cluster Configuration\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Now, you need to connect to an EKS cluster by generating a file which is known as a kubeconfig. By default, the kubeconfig files will be merged or written into your ~/.kube/config file, or if you have a $KUBECONFIG variable set, into the first file in that list (more on the $KUBECONFIG variable later).\"}),`\n`,(0,n.jsx)(e.p,{children:\"Again, I break out in hives around anything to do with YAML files and merging multiple configurations into one default file sounds like an easy recipe for disaster or rolling out the wrong changes to production late at night. Ideally, I\\u2019d like to keep all my configurations separate and specify them when I need them. I also want to avoid editing files or updating labels in dense, hard to read YAML.\"}),`\n`,(0,n.jsx)(e.p,{children:\"If you have more than one EKS cluster, and perhaps in separate AWS accounts, I want to make sure I keep them straight. The first step is to create a cluster configuration file and save it to a specific file:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`$ AWS_PROFILE=production AWS_DEFAULT_REGION=us-west-2 \\\\\naws eks update-kubeconfig --name=prodEKS --alias=production \\\\\n--kubeconfig=~/.kube/config-prod-us-west-2\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"One of the great tools you should check out is EKSCTL which has a similar use case:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`$ eksctl utils write-kubeconfig --cluster=prodEKS \\\\\n--kubeconfig=~/.kube/config-prod-us-west-2 \\\\\n--set-kubeconfig-context --profile=production \\\\\n--region=us-west-2\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"I also like to use the --auto-kubeconfig option instead of --kubeconfig because it will save the file in ~/.kube/clusters/\",(0,n.jsx)(\"clustername\",{children:\" by default.\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Now, you can access your cluster by name, for example:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`$ AWS_PROFILE=prod kubectl get pods -A -o wide \\\\\n--kubeconfig=~/.kube/config-prod-us-west-2\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"So it gets a bit hairy to keep listing the file to specify which cluster you want to connect with. There must be a better way to do this, and there is luckily a way to specify a \",(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/#the-kubeconfig-environment-variable\",children:\"context and merge files\"}),\" to get this to work.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"So let\\u2019s say that all your cluster configurations are stored in separate files (which I like) and they all have a convention of starting with ~/.kube/config-* or exist in a subdirectory like ~/.kube/clusters/*. Now you can create a KUBECONFIG colon-separated list of the files like so:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{children:`\nFILES=(~/.kube/config-*); IFS=: eval 'export KUBECONFIG=\"\\${FILES[*]}\"'\n\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"Add the above snippet to your ~/.bash_aliases (or whatever bashrc script you prefer) and then start a new shell and you\\u2019ll be able to select a cluster by context:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{children:`\n$ exec bash -l # This just loads my exports if I have updated anything\n$ AWS_PROFILE=production kubectl get pods -A -o wide --context=production\n\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"So you will need to specify your AWS profile (to gain access credentials to your assumed role for EKS) and also specify the context in order to choose a cluster to connect to. But I find it fairly usable and keeps all my configuration files in separate locations while still being relatively easy to maintain and manage. I also remove the accidental possibility of accessing the incorrect cluster or environment and wreaking havoc.\"}),`\n`,(0,n.jsxs)(e.h3,{id:\"conclusion\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#conclusion\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Conclusion\"]}),`\n`,(0,n.jsx)(e.p,{children:\"It is possible to keep YAML file configuration and management of EKS kubernetes clusters separate and yet accessible with some flags that switch into the correct environment. Adding and removing clusters and credentials is easily managed in the filesystem and without editing files directly. Also, defaults are removed so that a command does not get executed on the wrong cluster inadvertently.\"})]})}function v(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(u,t)})):u(t)}var I=v;return b(S);})();\n;return Component;"
  },
  "_id": "blog/posts/how-to-make-kubernetes-config-files-not-suck.mdx",
  "_raw": {
    "sourceFilePath": "blog/posts/how-to-make-kubernetes-config-files-not-suck.mdx",
    "sourceFileName": "how-to-make-kubernetes-config-files-not-suck.mdx",
    "sourceFileDir": "blog/posts",
    "contentType": "mdx",
    "flattenedPath": "blog/posts/how-to-make-kubernetes-config-files-not-suck"
  },
  "type": "BlogPost",
  "computedSlug": "how-to-make-kubernetes-config-files-not-suck"
}